{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-08-26T12:25:54.891825Z",
     "start_time": "2025-08-26T12:25:54.860161Z"
    }
   },
   "source": [
    "from importlib.metadata import version\n",
    "\n",
    "pkgs = [\n",
    "    \"matplotlib\",\n",
    "    \"numpy\",\n",
    "    \"tiktoken\",\n",
    "    \"torch\",\n",
    "    # \"tensorflow\", # for open ai pretrained wights\n",
    "]\n",
    "\n",
    "for p in pkgs:\n",
    "    print(f\"{p}: {version(p)}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matplotlib: 3.10.5\n",
      "numpy: 2.3.2\n",
      "tiktoken: 0.9.0\n",
      "torch: 2.2.2\n"
     ]
    }
   ],
   "execution_count": 88
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-26T12:25:54.902129Z",
     "start_time": "2025-08-26T12:25:54.898920Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from gpt_helpers import GPTModel\n",
    "\n",
    "GPT_CONFIG_124M = {\n",
    "    'vocab_size': 50257,  # vocab size\n",
    "    'context_length': 256,  # context length\n",
    "    'emb_dim': 768,  # embedding dimension\n",
    "    'n_layers': 12,  # number of transformer blocks\n",
    "    'n_heads': 12,  # number of attention heads\n",
    "    'drop_rate': 0.1,  # dropout rate\n",
    "    'qkv_bias': False,  # whether to use bias in the query, key, and value weights\n",
    "}"
   ],
   "id": "667b79cc479c0cb7",
   "outputs": [],
   "execution_count": 89
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-26T12:25:55.953135Z",
     "start_time": "2025-08-26T12:25:54.913583Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "\n",
    "torch.manual_seed(456)\n",
    "\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "# model.eval()    # this shows the model architecture\n",
    "model.eval();\n"
   ],
   "id": "a73ea61ac1ebfa1b",
   "outputs": [],
   "execution_count": 90
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-26T12:25:55.977282Z",
     "start_time": "2025-08-26T12:25:55.973560Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import tiktoken\n",
    "from gpt_helpers import generate_text_simple\n",
    "\n",
    "\n",
    "def text_to_token_ids(text, tokenizer):\n",
    "    encoded = tokenizer.encode(text, allowed_special={\"<|endoftext|>\"})\n",
    "    encoded_tensor = torch.tensor(encoded).unsqueeze(0)  #adding batch dimension for the current architecture\n",
    "    return encoded_tensor\n",
    "\n",
    "\n"
   ],
   "id": "a4cc3a40f48e20a6",
   "outputs": [],
   "execution_count": 91
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-26T12:25:55.990333Z",
     "start_time": "2025-08-26T12:25:55.985665Z"
    }
   },
   "cell_type": "code",
   "source": [
    "start_context = \"Every effort moves you\"\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "token_ids = text_to_token_ids(start_context, tokenizer)\n",
    "print(token_ids)"
   ],
   "id": "aa080f18ae2826bc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[6109, 3626, 6100,  345]])\n"
     ]
    }
   ],
   "execution_count": 92
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-26T12:25:56.016044Z",
     "start_time": "2025-08-26T12:25:56.010554Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def token_ids_to_text(token_ids, tokenizer):\n",
    "    flat = token_ids.squeeze(0)  # remove batch dimension\n",
    "    return tokenizer.decode(flat.tolist())\n",
    "\n",
    "\n",
    "print(token_ids_to_text(token_ids, tokenizer))"
   ],
   "id": "7609d7490ba36d08",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Every effort moves you\n"
     ]
    }
   ],
   "execution_count": 93
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-26T12:25:56.523043Z",
     "start_time": "2025-08-26T12:25:56.030085Z"
    }
   },
   "cell_type": "code",
   "source": [
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(start_context, tokenizer),\n",
    "    max_new_tokens=10,\n",
    "    context_size=GPT_CONFIG_124M['context_length']\n",
    ")\n",
    "\n",
    "print(token_ids.squeeze(0))"
   ],
   "id": "9796441d787f47d2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 6109,  3626,  6100,   345, 13443, 37191, 25420, 23390, 35735, 37542,\n",
      "        27518, 24287, 31523,  8074])\n"
     ]
    }
   ],
   "execution_count": 94
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-26T12:25:56.539735Z",
     "start_time": "2025-08-26T12:25:56.534193Z"
    }
   },
   "cell_type": "code",
   "source": "print(token_ids_to_text(token_ids, tokenizer))",
   "id": "98f23c49219cca6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Every effort moves you vague trousers deepest cyclistsurnal rpm discourage northeast breaches Hom\n"
     ]
    }
   ],
   "execution_count": 95
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-26T12:25:56.565056Z",
     "start_time": "2025-08-26T12:25:56.560015Z"
    }
   },
   "cell_type": "code",
   "source": "print(token_ids[0, :5])",
   "id": "13da4f20659fa484",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 6109,  3626,  6100,   345, 13443])\n"
     ]
    }
   ],
   "execution_count": 96
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 5.1.2 calculating the text generation loss: Cross entropy  and perplexity",
   "id": "fb273570e4386e22"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-26T12:25:56.589184Z",
     "start_time": "2025-08-26T12:25:56.582500Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(text_to_token_ids(\"every effort moves\", tokenizer))\n",
    "print(text_to_token_ids(\"I really like\", tokenizer))\n",
    "print(text_to_token_ids(\" effort moves you\", tokenizer))\n",
    "print(text_to_token_ids(\" really like chocolate\", tokenizer))"
   ],
   "id": "7e4d83e63b6d5a86",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[16833,  3626,  6100]])\n",
      "tensor([[  40, 1107,  588]])\n",
      "tensor([[3626, 6100,  345]])\n",
      "tensor([[ 1107,   588, 11311]])\n"
     ]
    }
   ],
   "execution_count": 97
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-26T12:25:56.608048Z",
     "start_time": "2025-08-26T12:25:56.603806Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# lets look at some example of logits\n",
    "\n",
    "inputs = torch.tensor([[16833, 3626, 6100],\n",
    "                       [40, 1107, 588]])\n",
    "\n",
    "targets =  torch.tensor([[3626, 6100,  345],\n",
    "                         [ 1107,   588, 11311]])\n",
    "\n"
   ],
   "id": "b28c81e89d5bde4b",
   "outputs": [],
   "execution_count": 98
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-26T12:25:56.661620Z",
     "start_time": "2025-08-26T12:25:56.622412Z"
    }
   },
   "cell_type": "code",
   "source": [
    "with torch.no_grad():\n",
    "    logits = model(inputs)\n",
    "\n",
    "print(logits.shape)\n"
   ],
   "id": "df4b89995146597d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 50257])\n"
     ]
    }
   ],
   "execution_count": 99
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-26T12:25:56.682385Z",
     "start_time": "2025-08-26T12:25:56.672056Z"
    }
   },
   "cell_type": "code",
   "source": [
    "probas = torch.softmax(logits, dim=-1)\n",
    "probas.shape"
   ],
   "id": "c5b730c5711f1cc6",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 50257])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 100
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-26T12:25:56.698614Z",
     "start_time": "2025-08-26T12:25:56.692131Z"
    }
   },
   "cell_type": "code",
   "source": "probas",
   "id": "3125c72bb6cfeaa",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1.5637e-05, 5.7691e-05, 6.2597e-05,  ..., 1.7882e-05,\n",
       "          1.6705e-05, 1.5272e-05],\n",
       "         [1.5244e-05, 1.2207e-05, 2.5086e-05,  ..., 1.1783e-05,\n",
       "          1.5645e-05, 1.5306e-05],\n",
       "         [1.7312e-05, 6.8765e-05, 1.0261e-05,  ..., 1.9064e-05,\n",
       "          2.3313e-05, 1.9704e-05]],\n",
       "\n",
       "        [[1.0964e-05, 2.4615e-05, 3.3088e-05,  ..., 9.7370e-06,\n",
       "          4.9542e-06, 4.2242e-05],\n",
       "         [7.6122e-06, 1.5710e-05, 5.3961e-05,  ..., 1.1088e-05,\n",
       "          1.7431e-05, 1.1257e-05],\n",
       "         [1.2937e-05, 6.1834e-06, 6.7389e-06,  ..., 1.4765e-05,\n",
       "          8.9612e-06, 2.8780e-05]]])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 101
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-26T12:25:56.719897Z",
     "start_time": "2025-08-26T12:25:56.714999Z"
    }
   },
   "cell_type": "code",
   "source": [
    "token_ids = torch.argmax(probas, dim=-1, keepdim=True)\n",
    "print(\"Token IDs:\\n\", token_ids)\n",
    "# token_ids_to_text(preds, tokenizer)"
   ],
   "id": "f0d23174b61035a0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token IDs:\n",
      " tensor([[[ 5365],\n",
      "         [13774],\n",
      "         [30197]],\n",
      "\n",
      "        [[41229],\n",
      "         [31634],\n",
      "         [ 7710]]])\n"
     ]
    }
   ],
   "execution_count": 102
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-26T12:25:56.740191Z",
     "start_time": "2025-08-26T12:25:56.736529Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(f\"Targets batch 1: {token_ids_to_text(targets[0], tokenizer)}\")\n",
    "print(f\"ouputs batch 1: {token_ids_to_text(token_ids[0].flatten(), tokenizer)}\")"
   ],
   "id": "27904dd24672bb75",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Targets batch 1:  effort moves you\n",
      "ouputs batch 1:  relatively crying Northwestern\n"
     ]
    }
   ],
   "execution_count": 103
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-26T12:25:56.760956Z",
     "start_time": "2025-08-26T12:25:56.756147Z"
    }
   },
   "cell_type": "code",
   "source": "targets[txt_idx]",
   "id": "6cee5e06e5bd2454",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1107,   588, 11311])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 104
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-26T12:25:56.781815Z",
     "start_time": "2025-08-26T12:25:56.775593Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# what iss the probability of the target token for the target ( actually what it should have been )\n",
    "txt_idx = 0\n",
    "target_probas1  = probas[txt_idx, [0,1,2], targets[txt_idx]]\n",
    "print(\"text 1:\", target_probas1)\n",
    "# ideally we want to increase the above probability score during training"
   ],
   "id": "e0fa493f687890ca",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text 1: tensor([2.7467e-05, 6.1473e-05, 1.5830e-05])\n"
     ]
    }
   ],
   "execution_count": 105
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-26T12:25:56.796602Z",
     "start_time": "2025-08-26T12:25:56.791510Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# what iss the probability of the target token for the target ( actually what it should have been )\n",
    "txt_idx = 1\n",
    "target_probas2  = probas[txt_idx, [0,1,2], targets[txt_idx]]\n",
    "print(\"text 2:\", target_probas2)"
   ],
   "id": "5f8640140770449e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text 2: tensor([3.0948e-05, 2.3746e-05, 8.7063e-06])\n"
     ]
    }
   ],
   "execution_count": 106
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-26T12:25:56.809716Z",
     "start_time": "2025-08-26T12:25:56.805002Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# whats the error?\n",
    "# compute the log probabilities\n",
    "log_probas  = torch.log(torch.cat((target_probas1, target_probas2)))\n",
    "print(log_probas)"
   ],
   "id": "e4095870bd1c79a9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-10.5025,  -9.6969, -11.0536, -10.3832, -10.6481, -11.6515])\n"
     ]
    }
   ],
   "execution_count": 107
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-26T12:26:24.308245Z",
     "start_time": "2025-08-26T12:26:24.303763Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# negative log likelihood\n",
    "-1 * torch.mean(log_probas)\n",
    "# the idea is to make this close to zero"
   ],
   "id": "34fe65a2a0f911ea",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(10.6560)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 109
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-26T12:28:22.734798Z",
     "start_time": "2025-08-26T12:28:22.730112Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(torch.log(torch.tensor([1.0])))\n",
    "print(torch.log(torch.tensor([0.00000000000003])))"
   ],
   "id": "3ed801c4e36ecea5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.])\n",
      "tensor([-31.1376])\n"
     ]
    }
   ],
   "execution_count": 110
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-26T12:32:01.022361Z",
     "start_time": "2025-08-26T12:32:01.017680Z"
    }
   },
   "cell_type": "code",
   "source": "logits.shape",
   "id": "86472c14f722426",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 50257])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 111
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-26T12:32:51.301229Z",
     "start_time": "2025-08-26T12:32:51.297094Z"
    }
   },
   "cell_type": "code",
   "source": [
    "logits_flat = logits.flatten(0,1)\n",
    "logits_flat.shape"
   ],
   "id": "46af680486257705",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 50257])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 112
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-26T12:33:41.798073Z",
     "start_time": "2025-08-26T12:33:41.790137Z"
    }
   },
   "cell_type": "code",
   "source": [
    "targets_flat = targets.flatten(0,1)\n",
    "targets_flat.shape"
   ],
   "id": "62fddfc80b857d3e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 113
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "targets_flat = targets.flatten(0,1)\n",
    "targets_flat.shape\n"
   ],
   "id": "51df23cbf8c5742d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-26T12:34:07.667205Z",
     "start_time": "2025-08-26T12:34:07.647749Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(10.6560)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 114,
   "source": [
    "# pytorch shortcut\n",
    "\n",
    "torch.nn.functional.cross_entropy(logits_flat,targets_flat)"
   ],
   "id": "4bb05048084e9fcd"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
