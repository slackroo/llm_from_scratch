{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-08-27T15:13:04.751087Z",
     "start_time": "2025-08-27T15:13:04.728973Z"
    }
   },
   "source": [
    "from importlib.metadata import version\n",
    "\n",
    "pkgs = [\n",
    "    \"matplotlib\",\n",
    "    \"numpy\",\n",
    "    \"tiktoken\",\n",
    "    \"torch\",\n",
    "    # \"tensorflow\", # for open ai pretrained wights\n",
    "]\n",
    "\n",
    "for p in pkgs:\n",
    "    print(f\"{p}: {version(p)}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matplotlib: 3.10.5\n",
      "numpy: 2.3.2\n",
      "tiktoken: 0.9.0\n",
      "torch: 2.2.2\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-27T15:13:07.254914Z",
     "start_time": "2025-08-27T15:13:04.795302Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from gpt_helpers import GPTModel\n",
    "\n",
    "GPT_CONFIG_124M = {\n",
    "    'vocab_size': 50257,  # vocab size\n",
    "    'context_length': 256,  # context length\n",
    "    'emb_dim': 768,  # embedding dimension\n",
    "    'n_layers': 12,  # number of transformer blocks\n",
    "    'n_heads': 12,  # number of attention heads\n",
    "    'drop_rate': 0.1,  # dropout rate\n",
    "    'qkv_bias': False,  # whether to use bias in the query, key, and value weights\n",
    "}"
   ],
   "id": "667b79cc479c0cb7",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.3.2 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"/Users/slackroo/Data_science/LLM/llm_from_scratch/.venv/lib/python3.11/site-packages/ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/Users/slackroo/Data_science/LLM/llm_from_scratch/.venv/lib/python3.11/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"/Users/slackroo/Data_science/LLM/llm_from_scratch/.venv/lib/python3.11/site-packages/ipykernel/kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/Users/slackroo/Data_science/LLM/llm_from_scratch/.venv/lib/python3.11/site-packages/tornado/platform/asyncio.py\", line 211, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/Users/slackroo/Library/Application Support/uv/python/cpython-3.11.9-macos-x86_64-none/lib/python3.11/asyncio/base_events.py\", line 608, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/Users/slackroo/Library/Application Support/uv/python/cpython-3.11.9-macos-x86_64-none/lib/python3.11/asyncio/base_events.py\", line 1936, in _run_once\n",
      "    handle._run()\n",
      "  File \"/Users/slackroo/Library/Application Support/uv/python/cpython-3.11.9-macos-x86_64-none/lib/python3.11/asyncio/events.py\", line 84, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/Users/slackroo/Data_science/LLM/llm_from_scratch/.venv/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 516, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"/Users/slackroo/Data_science/LLM/llm_from_scratch/.venv/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 505, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"/Users/slackroo/Data_science/LLM/llm_from_scratch/.venv/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 397, in dispatch_shell\n",
      "    await result\n",
      "  File \"/Users/slackroo/Data_science/LLM/llm_from_scratch/.venv/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 368, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"/Users/slackroo/Data_science/LLM/llm_from_scratch/.venv/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 752, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"/Users/slackroo/Data_science/LLM/llm_from_scratch/.venv/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 455, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"/Users/slackroo/Data_science/LLM/llm_from_scratch/.venv/lib/python3.11/site-packages/ipykernel/zmqshell.py\", line 577, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"/Users/slackroo/Data_science/LLM/llm_from_scratch/.venv/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3116, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/Users/slackroo/Data_science/LLM/llm_from_scratch/.venv/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3171, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"/Users/slackroo/Data_science/LLM/llm_from_scratch/.venv/lib/python3.11/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/Users/slackroo/Data_science/LLM/llm_from_scratch/.venv/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3394, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/Users/slackroo/Data_science/LLM/llm_from_scratch/.venv/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3639, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"/Users/slackroo/Data_science/LLM/llm_from_scratch/.venv/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3699, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/var/folders/6d/ydlrjs7x3_n6lhh19hn27v200000gn/T/ipykernel_46107/112225533.py\", line 1, in <module>\n",
      "    from gpt_helpers import GPTModel\n",
      "  File \"/Users/slackroo/Data_science/LLM/llm_from_scratch/notebooks/gpt_helpers.py\", line 1, in <module>\n",
      "    import torch\n",
      "  File \"/Users/slackroo/Data_science/LLM/llm_from_scratch/.venv/lib/python3.11/site-packages/torch/__init__.py\", line 1477, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"/Users/slackroo/Data_science/LLM/llm_from_scratch/.venv/lib/python3.11/site-packages/torch/functional.py\", line 9, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"/Users/slackroo/Data_science/LLM/llm_from_scratch/.venv/lib/python3.11/site-packages/torch/nn/__init__.py\", line 1, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"/Users/slackroo/Data_science/LLM/llm_from_scratch/.venv/lib/python3.11/site-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
      "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
      "  File \"/Users/slackroo/Data_science/LLM/llm_from_scratch/.venv/lib/python3.11/site-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
      "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "/Users/slackroo/Data_science/LLM/llm_from_scratch/.venv/lib/python3.11/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-27T15:13:08.742310Z",
     "start_time": "2025-08-27T15:13:07.344056Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "\n",
    "torch.manual_seed(456)\n",
    "\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "# model.eval()    # this shows the model architecture\n",
    "model.eval();\n"
   ],
   "id": "a73ea61ac1ebfa1b",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-27T15:13:08.794268Z",
     "start_time": "2025-08-27T15:13:08.789037Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import tiktoken\n",
    "from gpt_helpers import generate_text_simple\n",
    "\n",
    "\n",
    "def text_to_token_ids(text, tokenizer):\n",
    "    encoded = tokenizer.encode(text, allowed_special={\"<|endoftext|>\"})\n",
    "    encoded_tensor = torch.tensor(encoded).unsqueeze(0)  #adding batch dimension for the current architecture\n",
    "    return encoded_tensor\n",
    "\n",
    "\n"
   ],
   "id": "a4cc3a40f48e20a6",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-27T15:13:09.235069Z",
     "start_time": "2025-08-27T15:13:08.844634Z"
    }
   },
   "cell_type": "code",
   "source": [
    "start_context = \"Every effort moves you\"\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "token_ids = text_to_token_ids(start_context, tokenizer)\n",
    "print(token_ids)"
   ],
   "id": "aa080f18ae2826bc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[6109, 3626, 6100,  345]])\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-27T15:13:09.253354Z",
     "start_time": "2025-08-27T15:13:09.246847Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def token_ids_to_text(token_ids, tokenizer):\n",
    "    flat = token_ids.squeeze(0)  # remove batch dimension\n",
    "    return tokenizer.decode(flat.tolist())\n",
    "\n",
    "\n",
    "print(token_ids_to_text(token_ids, tokenizer))"
   ],
   "id": "7609d7490ba36d08",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Every effort moves you\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-27T15:13:09.811273Z",
     "start_time": "2025-08-27T15:13:09.287839Z"
    }
   },
   "cell_type": "code",
   "source": [
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(start_context, tokenizer),\n",
    "    max_new_tokens=10,\n",
    "    context_size=GPT_CONFIG_124M['context_length']\n",
    ")\n",
    "\n",
    "print(token_ids.squeeze(0))"
   ],
   "id": "9796441d787f47d2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 6109,  3626,  6100,   345, 13443, 37191, 25420, 23390, 35735, 37542,\n",
      "        27518, 24287, 31523,  8074])\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-27T15:13:09.845271Z",
     "start_time": "2025-08-27T15:13:09.842339Z"
    }
   },
   "cell_type": "code",
   "source": "print(token_ids_to_text(token_ids, tokenizer))",
   "id": "98f23c49219cca6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Every effort moves you vague trousers deepest cyclistsurnal rpm discourage northeast breaches Hom\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-27T15:13:09.874179Z",
     "start_time": "2025-08-27T15:13:09.870239Z"
    }
   },
   "cell_type": "code",
   "source": "print(token_ids[0, :5])",
   "id": "13da4f20659fa484",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 6109,  3626,  6100,   345, 13443])\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 5.1.2 calculating the text generation loss: Cross entropy  and perplexity",
   "id": "fb273570e4386e22"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-27T15:13:09.899401Z",
     "start_time": "2025-08-27T15:13:09.892968Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(text_to_token_ids(\"every effort moves\", tokenizer))\n",
    "print(text_to_token_ids(\"I really like\", tokenizer))\n",
    "print(text_to_token_ids(\" effort moves you\", tokenizer))\n",
    "print(text_to_token_ids(\" really like chocolate\", tokenizer))"
   ],
   "id": "7e4d83e63b6d5a86",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[16833,  3626,  6100]])\n",
      "tensor([[  40, 1107,  588]])\n",
      "tensor([[3626, 6100,  345]])\n",
      "tensor([[ 1107,   588, 11311]])\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-27T15:13:09.935084Z",
     "start_time": "2025-08-27T15:13:09.931895Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# lets look at some example of logits\n",
    "\n",
    "inputs = torch.tensor([[16833, 3626, 6100],\n",
    "                       [40, 1107, 588]])\n",
    "\n",
    "targets =  torch.tensor([[3626, 6100,  345],\n",
    "                         [ 1107,   588, 11311]])\n",
    "\n"
   ],
   "id": "b28c81e89d5bde4b",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-27T15:13:10.013205Z",
     "start_time": "2025-08-27T15:13:09.964271Z"
    }
   },
   "cell_type": "code",
   "source": [
    "with torch.no_grad():\n",
    "    logits = model(inputs)\n",
    "\n",
    "print(logits.shape)\n"
   ],
   "id": "df4b89995146597d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 50257])\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-27T15:13:10.071262Z",
     "start_time": "2025-08-27T15:13:10.063116Z"
    }
   },
   "cell_type": "code",
   "source": [
    "probas = torch.softmax(logits, dim=-1)\n",
    "probas.shape"
   ],
   "id": "c5b730c5711f1cc6",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 50257])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-27T15:13:23.378579Z",
     "start_time": "2025-08-27T15:13:23.372768Z"
    }
   },
   "cell_type": "code",
   "source": "probas",
   "id": "3125c72bb6cfeaa",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1.5637e-05, 5.7691e-05, 6.2597e-05,  ..., 1.7882e-05,\n",
       "          1.6705e-05, 1.5272e-05],\n",
       "         [1.5244e-05, 1.2207e-05, 2.5086e-05,  ..., 1.1783e-05,\n",
       "          1.5645e-05, 1.5306e-05],\n",
       "         [1.7312e-05, 6.8765e-05, 1.0261e-05,  ..., 1.9064e-05,\n",
       "          2.3313e-05, 1.9704e-05]],\n",
       "\n",
       "        [[1.0964e-05, 2.4615e-05, 3.3088e-05,  ..., 9.7370e-06,\n",
       "          4.9542e-06, 4.2242e-05],\n",
       "         [7.6122e-06, 1.5710e-05, 5.3961e-05,  ..., 1.1088e-05,\n",
       "          1.7431e-05, 1.1257e-05],\n",
       "         [1.2937e-05, 6.1834e-06, 6.7389e-06,  ..., 1.4765e-05,\n",
       "          8.9612e-06, 2.8780e-05]]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-27T15:13:23.404328Z",
     "start_time": "2025-08-27T15:13:23.399880Z"
    }
   },
   "cell_type": "code",
   "source": [
    "token_ids = torch.argmax(probas, dim=-1, keepdim=True)\n",
    "print(\"Token IDs:\\n\", token_ids)\n",
    "# token_ids_to_text(preds, tokenizer)"
   ],
   "id": "f0d23174b61035a0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token IDs:\n",
      " tensor([[[ 5365],\n",
      "         [13774],\n",
      "         [30197]],\n",
      "\n",
      "        [[41229],\n",
      "         [31634],\n",
      "         [ 7710]]])\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-27T15:13:23.442586Z",
     "start_time": "2025-08-27T15:13:23.438792Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(f\"Targets batch 1: {token_ids_to_text(targets[0], tokenizer)}\")\n",
    "print(f\"ouputs batch 1: {token_ids_to_text(token_ids[0].flatten(), tokenizer)}\")"
   ],
   "id": "27904dd24672bb75",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Targets batch 1:  effort moves you\n",
      "ouputs batch 1:  relatively crying Northwestern\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-27T15:21:33.653590Z",
     "start_time": "2025-08-27T15:21:33.640705Z"
    }
   },
   "cell_type": "code",
   "source": "# targets[txt_idx]",
   "id": "6cee5e06e5bd2454",
   "outputs": [],
   "execution_count": 37
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-27T15:13:29.552502Z",
     "start_time": "2025-08-27T15:13:29.543816Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# what iss the probability of the target token for the target ( actually what it should have been )\n",
    "txt_idx = 0\n",
    "target_probas1  = probas[txt_idx, [0,1,2], targets[txt_idx]]\n",
    "print(\"text 1:\", target_probas1)\n",
    "# ideally we want to increase the above probability score during training"
   ],
   "id": "e0fa493f687890ca",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text 1: tensor([2.7467e-05, 6.1473e-05, 1.5830e-05])\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-27T15:13:29.609833Z",
     "start_time": "2025-08-27T15:13:29.602889Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# what iss the probability of the target token for the target ( actually what it should have been )\n",
    "txt_idx = 1\n",
    "target_probas2  = probas[txt_idx, [0,1,2], targets[txt_idx]]\n",
    "print(\"text 2:\", target_probas2)"
   ],
   "id": "5f8640140770449e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text 2: tensor([3.0948e-05, 2.3746e-05, 8.7063e-06])\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-27T15:13:29.647437Z",
     "start_time": "2025-08-27T15:13:29.640215Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# whats the error?\n",
    "# compute the log probabilities\n",
    "log_probas  = torch.log(torch.cat((target_probas1, target_probas2)))\n",
    "print(log_probas)"
   ],
   "id": "e4095870bd1c79a9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-10.5025,  -9.6969, -11.0536, -10.3832, -10.6481, -11.6515])\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-27T15:13:29.671463Z",
     "start_time": "2025-08-27T15:13:29.665048Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# negative log likelihood\n",
    "-1 * torch.mean(log_probas)\n",
    "# the idea is to make this close to zero"
   ],
   "id": "34fe65a2a0f911ea",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(10.6560)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-27T15:13:29.693571Z",
     "start_time": "2025-08-27T15:13:29.687389Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(torch.log(torch.tensor([1.0])))\n",
    "print(torch.log(torch.tensor([0.00000000000003])))"
   ],
   "id": "3ed801c4e36ecea5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.])\n",
      "tensor([-31.1376])\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-27T15:13:29.738514Z",
     "start_time": "2025-08-27T15:13:29.734174Z"
    }
   },
   "cell_type": "code",
   "source": "logits.shape",
   "id": "86472c14f722426",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 50257])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-27T15:13:29.808559Z",
     "start_time": "2025-08-27T15:13:29.803037Z"
    }
   },
   "cell_type": "code",
   "source": [
    "logits_flat = logits.flatten(0,1)\n",
    "logits_flat.shape"
   ],
   "id": "46af680486257705",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 50257])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-27T15:13:29.860070Z",
     "start_time": "2025-08-27T15:13:29.855877Z"
    }
   },
   "cell_type": "code",
   "source": [
    "targets_flat = targets.flatten(0,1)\n",
    "targets_flat.shape"
   ],
   "id": "62fddfc80b857d3e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-27T15:13:29.883353Z",
     "start_time": "2025-08-27T15:13:29.877851Z"
    }
   },
   "cell_type": "code",
   "source": [
    "targets_flat = targets.flatten(0,1)\n",
    "targets_flat.shape\n"
   ],
   "id": "51df23cbf8c5742d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-27T15:13:29.913117Z",
     "start_time": "2025-08-27T15:13:29.901248Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# pytorch shortcut\n",
    "\n",
    "torch.nn.functional.cross_entropy(logits_flat,targets_flat)"
   ],
   "id": "4bb05048084e9fcd",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(10.6560)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Calculating the loss",
   "id": "b37c009a432d9f5b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-27T15:16:40.033700Z",
     "start_time": "2025-08-27T15:16:40.029427Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import urllib.request\n",
    "\n",
    "with open('docs/the-verdict.txt','r',encoding='utf-8') as f:\n",
    "    raw_text=f.read()"
   ],
   "id": "338f9b55df9a5e6f",
   "outputs": [],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-27T15:17:44.246043Z",
     "start_time": "2025-08-27T15:17:44.241501Z"
    }
   },
   "cell_type": "code",
   "source": "raw_text[:100]",
   "id": "27f83dc75532528a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I HAD always thought Jack Gisburn rather a cheap genius--though a good fellow enough--so it was no g'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-27T15:18:56.271463Z",
     "start_time": "2025-08-27T15:18:56.257439Z"
    }
   },
   "cell_type": "code",
   "source": [
    "total_characters = len(raw_text)\n",
    "total_tokens = len(tokenizer.encode(raw_text))\n",
    "\n",
    "print(f\"Total Characters: {total_characters}\")\n",
    "print(f\"Total Tokens: {total_tokens}\")"
   ],
   "id": "9bcc6256c02ca931",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Characters: 20479\n",
      "Total Tokens: 5145\n"
     ]
    }
   ],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-27T15:27:29.151139Z",
     "start_time": "2025-08-27T15:27:29.147439Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# split the data to training set and validation set\n",
    "\n",
    "from gpt_helpers import create_dataloaderV1\n",
    "\n",
    "# Train/Validation ratio\n",
    "train_ratio = 0.90\n",
    "split_idx  = int(len(raw_text) * train_ratio)\n",
    "train_data = raw_text[:split_idx]\n",
    "val_data = raw_text[split_idx:]\n"
   ],
   "id": "5fdb23272da5e4ae",
   "outputs": [],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-27T15:32:13.225464Z",
     "start_time": "2025-08-27T15:32:13.202176Z"
    }
   },
   "cell_type": "code",
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "train_loader = create_dataloaderV1(\n",
    "    train_data,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M['context_length'],\n",
    "    stride=GPT_CONFIG_124M['context_length'],\n",
    "    drop_last=True,\n",
    "    shuffle=True,\n",
    "    num_workers=0,\n",
    ")\n",
    "\n",
    "val_loader  = create_dataloaderV1(\n",
    "    val_data,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M['context_length'],\n",
    "    stride=GPT_CONFIG_124M['context_length'],\n",
    "    drop_last=False,\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    ")\n",
    "\n"
   ],
   "id": "f45a46728a944a58",
   "outputs": [],
   "execution_count": 39
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-27T15:33:01.049150Z",
     "start_time": "2025-08-27T15:33:01.029058Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"Train loader\")\n",
    "\n",
    "for x,y in train_loader:\n",
    "    pass\n",
    "print(x.shape, y.shape)"
   ],
   "id": "da11a29e7aeebaa7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n"
     ]
    }
   ],
   "execution_count": 40
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-27T15:34:11.714414Z",
     "start_time": "2025-08-27T15:34:11.710827Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"Validation loader\")\n",
    "\n",
    "for x,y in val_loader:\n",
    "    pass\n",
    "print(x.shape, y.shape)"
   ],
   "id": "a7a2bd1af3d0f345",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loader\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n"
     ]
    }
   ],
   "execution_count": 41
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-28T06:48:18.754281Z",
     "start_time": "2025-08-28T06:48:18.685255Z"
    }
   },
   "cell_type": "code",
   "source": "x.numel()",
   "id": "8ca2e7928c96d347",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 42
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "2adf749b46ffcd72"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-28T06:51:23.248449Z",
     "start_time": "2025-08-28T06:51:23.186177Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_tokens = 0\n",
    "for input_batch, target_batch in train_loader:\n",
    "    train_tokens += input_batch.numel()\n",
    "\n",
    "val_tokens = 0\n",
    "for input_batch, target_batch in val_loader:\n",
    "    val_tokens += input_batch.numel()\n",
    "\n",
    "print(\"train tokens:\", train_tokens)\n",
    "print(\"val tokens:\", val_tokens)\n",
    "print(\"all tokens:\", train_tokens + val_tokens)"
   ],
   "id": "543169edce07b1b1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train tokens: 4608\n",
      "val tokens: 512\n",
      "all tokens: 5120\n"
     ]
    }
   ],
   "execution_count": 43
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-28T07:04:06.617291Z",
     "start_time": "2025-08-28T07:04:06.595648Z"
    }
   },
   "cell_type": "code",
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ],
   "id": "72a0b25fd720b05d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 44
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-28T07:07:40.314252Z",
     "start_time": "2025-08-28T07:07:40.301359Z"
    }
   },
   "cell_type": "code",
   "source": "len(train_loader)",
   "id": "44262636f5893a42",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 45
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-28T07:07:58.452483Z",
     "start_time": "2025-08-28T07:07:58.417445Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def calc_loss_batch(input_batch, target_batch, model, device):\n",
    "    input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
    "    logits = model(input_batch)\n",
    "    loss = torch.nn.functional.cross_entropy(logits.flatten(0,1), target_batch.flatten())\n",
    "    return loss\n",
    "\n",
    "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
    "    total_loss = 0.0\n",
    "    if len(data_loader) == 0:\n",
    "        return float(\"nan\")\n",
    "    elif num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        # Reduce the number of batches to match the total number of batches in the dataloader\n",
    "        # if num_batches excceds the number of batches in  the data loader\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            total_loss += loss.item()\n",
    "        else:\n",
    "            break\n",
    "    return total_loss / num_batches\n",
    "\n"
   ],
   "id": "8e560a5a5f127298",
   "outputs": [],
   "execution_count": 46
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-28T07:11:01.474029Z",
     "start_time": "2025-08-28T07:10:51.642654Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# for reproducability due to thee shuffling in the dataloader\n",
    "torch.manual_seed(123)\n",
    "\n",
    "with torch.no_grad():\n",
    "    train_loss = calc_loss_loader(train_loader, model, device)\n",
    "    val_loss = calc_loss_loader(val_loader, model, device)\n",
    "\n",
    "print(f\"train loss: {train_loss:.4f}, val loss: {val_loss:.4f}\")"
   ],
   "id": "438527621a67a6d2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 10.9898, val loss: 10.9956\n"
     ]
    }
   ],
   "execution_count": 47
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#  Perplexity",
   "id": "d479d6fd3352a7d6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-28T07:49:32.353763Z",
     "start_time": "2025-08-28T07:49:32.343224Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# perplexity score, it basically says how unsure the model is about the words it predicts\n",
    "torch.exp(torch.tensor(train_loss))"
   ],
   "id": "2d3c0adc7e8c01cb",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(59267.2891)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 49
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# training the LLM",
   "id": "a4f59ff674e18881"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "580cf30974d33582"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
